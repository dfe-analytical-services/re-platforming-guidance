# Case Studies{#case_studies}

The case studies included in this guide were identified through a cross-Department working group.  This covered analysts who were new to code-based models who had to learn R and ask experts to help up to those who were already experts in this area so we hope that the case studies showcased will provide useful learning points for everybody, no matter where you are in your learning journey.  We hope to include additional case studies in future so please [get in touch](mailto:modellingandqa@Educationgovuk.onmicrosoft.com) if you would like to add yours!  

## Schools Block National Funding Formula Model (SB NFF)
The SB NFF model carries out funding allocations for the schools block element of the Dedicated Schools Grant.  Individual schools and pupil characteristics are used to underpin the formula allocation for more than 20,000 schools which meant that running the model in Excel involved several linked workbooks and data processing and manipulation in other files.  Whilst there was a really good analytical argument to be made for re-platforming this model due to the technical challenges, one of the *biggest barriers* was that policy colleagues were initially reluctant for a re-platform as they wanted to be able to interact with the model themselves.

### Model details
The schools block NFF Excel spreadsheet model often took most of a day for two analysts to update new changes for scenario costing. It was also very prone to error given the number of manual interventions required therefore the aim of the re-platform was to create a cleaner pipeline for scenario costing.

### Replatform details
The first phase of the re-platform took a few months of a single analysts time to create the initial model, alongside Business As Usual work.  At this stage it was a "third-build" model and the analyst was able to match outputs from the existing model to fully QA'ed models to ensure the R model was working correctly.

The second phase of the re-platform involved other members of the team implementing further QA and error checking into the model.  An important change that was needed at this stage was a restructure of the code to allow for an Rmarkdown document to be created for policy colleagues.  This was created iteratively, with a lot of engagement from working level policy colleagues in order to capture the right level of detail in an easy to understand way before taking more senior stakeholders and the model SRO through the walkthrough for sign-off.  After this, the R model became their main model for the following allocation cycle.  

### Benefits
There were immediate benefits from the first phase - updating the model parameters became easier on the new platform than in Excel.  Other analysts in the team who took on the rest of the NFF re-development were totally new to R but had experience of other languages. They were able to use what had been done in the first phase to learn the language in a hands-on way by developing the next phase.

The model is now much more efficient, running in seconds rather than tens of minutes.  The new model can query directly to SQL compared to the previous Excel model, which required generating/exporting code, then loading the data in.  This was a really big improvement and *greatly enhances QA* as the SQL query is directly within the model therefore it's transparent *and* by querying the data directly it removes risk of both copying and pasting errors or using the wrong file.  

The team is now much better equipped and more efficient in their support to policy colleagues with development of the formula.  The re-platformed model meant the team were able to provide better support to last year’s SR because it was much quicker and easier to run scenarios and using the skills they'd developed, analysts produced an output dashboard that included a number of different comparisons and breakdowns, which helped the policy team understand and communicate the impact of a particular funding scenario.

The team use repos within Azure DevOps and git for tracking changes and version control. This has improved governance of the model,  commissioning QA task processes and their ability to work on a single model collaboratively. The NFF team have also used their new R skills to produce other dashboards and tools using R and RShiny to support the policy team with correspondence, PMQs. etc

There have also been wider benefits too.  The knowledge developed from the model re-platform has been used in subsequent model development across the division as well.

### Practical tips from the team

* Training - On moving to R, team members had different levels of expertise, learning trajectories and amounts of time available to dedicate to on-the-job learning. There wasn’t a structured plan for what needed to be learnt, and training was very self-directed, which was manageable but tricky. Having an agreement in place for what fundamental learning needs to take place and allowing time for that training to be undertaken would be helpful for any re-platforming project.

* Governance - There were concerns from the policy team about whether they’d be able to understand the model and whether they’d ever have enough confidence in it to sign it off.  The SRO would normally be walked through the Excel model step by step so the team had to think carefully about how to retain similar confidence in the R model. They achieved this by highlighting the benefits of re-platforming and by providing walkthroughs of key chunks of the code.  But, it did take some effort from both sides – analysts needed to make sure code was clearly written and reasonably accessible, and the policy team needed to put in some effort to understand and follow a code-based model walkthrough. Thinking about how the re-platformed model would impact governance processes (e.g. dual builds, policy walkthroughs) and how to manage those changes was really important.

* Resilience - Whilst there is a move towards using R more widely in DfE, it’s still something many people are learning and levels of expertise vary.  This needs to be kept in mind when developments are made to the model and as the team upskills further.  The team need to consider whether they can expect someone else coming into the team to be able to pick up the modelling and how much training they will need. Potentially this has its advantages as there is a good amount of technical and non-technical development to be had from working in their team, but it’s something they need to bear in mind when making any substantive developments.

## Student Loan Earnings Model
The [Student Loan Earnings Model](https://assets.publishing.service.gov.uk/government/uploads/system/uploads/attachment_data/file/811624/Student_loan_forecasts_2018-19_-_technical_notes.pdf) is a micro-simulation model that forecasts future annual graduate earnings at an individual level, which are used to determine future student loan repayments that the Department expects to receive on its expenditure on student loans.  

The model is audited externally by the National Audit Office, who maintain a shadow-build version of the model. Whilst this is needed for NAO's own purposes, it adds value to the DfE process as well by acting as a dual build.  

It was re-platformed from Microsoft Excel to R over several phases, with the re-platform bringing out nuances in both the model methodology and implementation details. The process was carried out collaboratively by a small team, using version control software to track and merge changes.


### Model details
The Earnings Model forecasts future annual earnings using a collection of submodels which: 

* For a given borrower's characteristics and history, predict next year’s employment status (from 4 possible states),
* If employed, forecast earnings using the suitable regression model.

The Excel-based model implementation had several issues which made it complex to update and slow to run: 

* It required manual extraction of data stored externally in SQL databases - the Excel spreadsheet contained sample SQL code to extract the datasets, before the data was copied to an additional tab in the workbook to be used. 
* Key steps within the model's implementation logic were hidden within complex Excel formulae, and were time-consuming to trace and debug.
* The Excel model was only able to run a small sample (200,000) of the almost 5 million borrowers in the system, so it lacked capacity to model the entire population.
* An additional issue was that platform-specific issues in Excel (such as how random numbers are generated and stored) caused differences in reproducing simulation results on other platforms. 

The aim of the re-platform was to improve readability, reliability and speed of implementation, to permit larger model runs, and set up a robust version control methodology for future model improvement.


### Replatform details
The re-platform took place over phases by a small team of analysts - all quite new to the model but proficient in R and other coding languages.

They started by copying the workflow from the existing implementation^[This may have been done differently if re-platforming based directly on mathematical formulae rather than from an implementation.] - following the logic of calculation steps displayed within the cell formulae of the Excel spreadsheet, and incrementally ported each calculation step of the methodology across.

As part of the re-platform, lookup tables from Excel were exported as datasets but external SQL databases were queried directly from the re-platformed model.  This brought several benefits including ensuring changes to the code were only needed in one place, reducing the risk of copying and pasting errors by accessing the data directly and allowing the entire dataset to be used within the model, instead of only a small sample.

The team used version control within an Azure DevOps repo to carry out continuous code review during development. This meant that quality assurance occurred incrementally - potentially eliminating the need for a detailed 'full' quality assurance after the re-platform was completed.  However, wider [unit testing](https://dfe-analytical-services.github.io/good-code-practice/testing.html#unit-testing) may have been beneficial to provide assurance of the end to end process.

One reocurring issue was whether the model methodology should be improved at the point of the re-platform, or whether it should be a like-for-like implementation, with future scope for model methodology improvement. It was decided to keep a like-for-like implementation to ensure that the replatformed model behaved correctly, although the tradeoff was a slower timeline for model improvement.

The re-platform was carried out prior to writing documentation. It was unclear to the team whether it was more advantageous to document along the way given the analyst time available. In hindsight this may have been a better option as it would mean analysts documenting each section they had replatformed.

### Benefits
One of the biggest benefits from this re-platform is that the model can utilise the full dataset and model outcomes for individual borrowers based on their full characteristics, rather than scaling results from a modelled subsample of aggregated borrowers.

In addition to this, the replatform has led to other benefits:

* The model methodology is easier to understand, with model parameters and subprocesses defined in a more readable way. This makes it easier to tweak the model for model runs, and simpler for new team members familiarising themselves with the model.
* Model run times are quicker, and it is easier for a single team member to execute multiple model runs.
* A more robust version-control system is in place which means that model changes are easier to quality assure, model versions can be tracked and compared, and the model development process is more transparent for external audit.


### Technical tips
The team found that switching to a code-based implementation led to additional questions during the re-platform, which may recur in other projects. Some of these are listed below:

* Use appropriately named functions and variable names to simplify the readability
* Regular checkins if multiple analysts working on code (code style/naming conventions)
* Camel case or snake case for functions, starting with a verb (e.g. calcNewBalance)
* Think about variable names - switching between SQL and R - upper case vs camel case/Pascal case
* Agree and decide on the optimum Git branching strategy - e.g. using merge vs rebase, fast forward history
* Don’t store large binary files in Git if you can help it!
* Consider using lists of lists to store the output data (memory issues)
* Consider using data.table() package over dplyr for speed with large datasets